{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51d249f-1f21-471c-8769-a04939fafc5c",
   "metadata": {},
   "source": [
    "## Brain Tumor Classification\n",
    "\n",
    "The task is to use classification algorithms to categorize 4 types of brain tumors.\n",
    "\n",
    " * Glioma Tumor\n",
    " * Meningioma Tumor\n",
    " * No Tumor\n",
    " * Pituitary Tumor\n",
    "\n",
    "**Dataset:** [click here](https://www.kaggle.com/datasets/prathamgrover/brain-tumor-classification/download?datasetVersionNumber=1) to download the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa024a4-34de-450c-b323-a80172b8be5f",
   "metadata": {},
   "source": [
    "###  1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d08c0c-5029-4fd5-94f7-0a31513a478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86d0f2-9290-4011-b496-67413b3964a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations (you can customize these)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a consistent size\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation: random horizontal flip\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize pixel values\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd8fb9-f63d-435f-9390-187215ea0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test data directory\n",
    "TRAIN_IMG_DIR = 'data\\brain-tumor\\train'\n",
    "TEST_IMG_DIR = 'data\\brain-tumor\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af99a65-673e-4798-ac9e-6b14e1cda2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images(data_dir):\n",
    "    # Get a list of subfolders (tumor class types)\n",
    "    subfolders = os.listdir(data_dir)\n",
    "    \n",
    "    # Create a subplot for each subfolder\n",
    "    num_subplots = len(subfolders)\n",
    "    rows, cols = 2, 4  # 2 rows and 4 columns for each subplot\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(8, 4))\n",
    "    \n",
    "    # Iterate through each subfolder\n",
    "    for i, subfolder in enumerate(subfolders):\n",
    "        subfolder_path = os.path.join(data_dir, subfolder)\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        \n",
    "        # Randomly select 8 images from the subfolder\n",
    "        selected_images = random.sample(image_files, 8)\n",
    "        \n",
    "        # Create a subplot for the current subfolder\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Display the tumor class type as the subplot title\n",
    "        ax.set_title(subfolder)\n",
    "        \n",
    "        # Display the selected images in the subplot\n",
    "        for image_file in selected_images:\n",
    "            image_path = os.path.join(subfolder_path, image_file)\n",
    "            img = Image.open(image_path)\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')  # Turn off axis labels\n",
    "            \n",
    "    # Remove any empty subplots (if there are fewer subfolders than subplots)\n",
    "    for i in range(num_subplots, rows * cols):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "    \n",
    "    # Adjust subplot layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0599f-d288-4eaa-b870-22b9376434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images('data/brain-tumor/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70b54b-b33a-45c9-aca7-99854602dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images_in_row(data_dir, num_images=8):\n",
    "    # Get a list of subfolder names in the data directory\n",
    "    subfolders = [subfolder for subfolder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, subfolder))]\n",
    "\n",
    "    # Loop through each subfolder\n",
    "    for subfolder in subfolders:\n",
    "        # Define the path to the tumor subfolder within the \"Training\" folder\n",
    "        subfolder_path = os.path.join(data_dir, subfolder)\n",
    "        print(f'Images path : {subfolder_path}')\n",
    "        \n",
    "        # Get a list of image files in the subfolder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        \n",
    "        # Randomly select 'num_images' images from the subfolder\n",
    "        selected_images = random.sample(image_files, num_images)\n",
    "        \n",
    "        # Create a horizontal row for displaying the images\n",
    "        fig, axes = plt.subplots(1, num_images, figsize=(16, 4))\n",
    "\n",
    "        # Display the selected images in the row\n",
    "        for i, image_file in enumerate(selected_images):\n",
    "            image_path = os.path.join(subfolder_path, image_file)\n",
    "            img = Image.open(image_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')  # Turn off axis labels\n",
    "\n",
    "        # Add a title at the bottom of the row using plt.title()\n",
    "        plt.suptitle(f'Images for class: {subfolder}', fontsize=18, fontweight='bold', y=0.8)\n",
    "            \n",
    "        \n",
    "        # Adjust subplot layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Display the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3f681-9b8b-45e2-a47e-0d8944b8f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images_in_row('data/brain-tumor/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ffc6f-1e01-40cc-86ed-53af4e5506e6",
   "metadata": {},
   "source": [
    "### 2. Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c50aa4-2bfb-4316-8ff5-dc17bb116078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations for train and test datasets.\n",
    "# These transformations include resizing, random cropping, random horizontal flipping, and normalization.\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),  # Randomly crop and resize the image to 224x224 pixels.\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally for data augmentation.\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor.\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image using precomputed mean and standard deviation.\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize the image to 256x256 pixels.\n",
    "        transforms.CenterCrop(224),  # Crop the center of the image to 224x224 pixels.\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor.\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image using precomputed mean and standard deviation.\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ec48f-c674-4ee6-9dad-d59983d8f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the root directory where your data is stored.\n",
    "data_dir = 'data/brain-tumor' # Update with the path to your data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e761e-6387-4dd3-a3fd-e6fc407e356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for both train and test data using ImageFolder.\n",
    "# ImageFolder automatically organizes your data into classes based on subfolders.\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f04494-8d19-423c-8ed1-05985cf8a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for train and test datasets.\n",
    "# Data loaders allow you to load data in batches for training and testing.\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673de6bc-bbe7-48b4-ac65-134060a606e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the size of the datasets (number of samples) for train and test.\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bdac04-4bfa-4d51-84a7-09eaf8d12358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class names based on the subfolders in the 'train' directory.\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a5411-9593-4921-a7a4-df87cb99ed54",
   "metadata": {},
   "source": [
    "### 3. Load the pretrained ResNet-50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555a3df-a750-4173-846f-398097631e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303bb61-caf0-4277-ba00-e77c6e0f6db8",
   "metadata": {},
   "source": [
    "### 4. Modify the final fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddd5c1-ce0e-4eb7-8385-d1571031f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56025608-6ef2-4717-8eb7-563083fdcd6a",
   "metadata": {},
   "source": [
    "### 5. Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17f3c3-c465-42ed-a2f2-6c0913a42351",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a24c00-7ef2-48ca-a930-e5ba1dcd35ef",
   "metadata": {},
   "source": [
    "### 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688b832-3596-48fb-aada-b9daf4c55e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train() # Set the model to training mode.\n",
    "            else:\n",
    "                model.eval()  # Set the model to evaluation mode.\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:.4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Determine whether a CUDA-capable GPU is available, and set the device accordingly.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Move the model to the selected device (GPU or CPU).\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Define the optimizer for training the model.\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Define a learning rate scheduler that adjusts the learning rate during training.\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "# In this scheduler, the learning rate is reduced by a factor of 0.1 every 7 epochs.\n",
    "\n",
    "# Train the model using the train_model function with the specified parameters.\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455465b-8258-44be-855d-9a7973959894",
   "metadata": {},
   "source": [
    "### 7. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5619dc-db5a-4d58-ac2b-ac6e736a6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model_ft.eval()\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total samples\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient calculation for evaluation to save memory and computation\n",
    "with torch.no_grad():\n",
    "    # Iterate through batches in the test data loader\n",
    "    for inputs, labels in dataloaders['Testing']:\n",
    "        # Move inputs and labels to the selected device (GPU or CPU)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass: compute model predictions\n",
    "        outputs = model_ft(inputs)\n",
    "        \n",
    "        # Get the class with the highest probability as the predicted class\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update the total count of samples\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Update the count of correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = 100 * correct / total\n",
    "print('Test accuracy: {:.2f}%'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c81cb3-9cee-425a-b60a-7b5b28b60a3f",
   "metadata": {},
   "source": [
    "### 8. Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c56c64-b738-4026-ac18-137bd91942c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "torch.save(model_ft.state_dict(), 'brain_tumor_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373d80b-296e-43df-95b0-c14cf399b271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
